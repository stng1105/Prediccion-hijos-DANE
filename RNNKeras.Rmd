---
title: "RNNKeras"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
datos <- read.csv("datos.csv")
```

```{r}
head(datos)
```




```{r}
datos= datos [, c(1,2,3,4,5,6,7,9,10,11,8)]
```

```{r}
head(datos)
```
X1= directorio
X2= p6020
X3= p6040
X4= p5502
X5= p6071
X6= P5667
X6= cant_personas_hogar
X7= i_hogar
X8= p5010
Y= hijos

```{r}
colnames(datos) <- c("X", "X1", "X2","X3", "X4","X5", "X6","X7","X8", "X9", "Y")
```

```{r}
head(datos)
```

```{r}
datos_sel <- subset(datos, select= c('X2','X3','X4','X5','X6','X7','X8','Y'))
```

```{r}
library(knitr)
library(tidyverse)
library(keras)
library(lime)
library(tidyquant)
library(rsample)
library(recipes)
library(yardstick)
library(corrr)
```



```{r}
glimpse(datos_sel)
```

```{r}
dataset <- datos_sel %>%
   select(-X5) %>%
   drop_na() %>%
   select (Y, everything())

glimpse(dataset)
```

```{r}
set.seed(840)
train_test_split <- initial_split(dataset, prop=0.9)
train_test_split
```

```{r}
train_tbl <- training(train_test_split)
test_tbl  <- testing(train_test_split)
```


```{r}
rec_obj <- recipe( Y ~ ., data= train_tbl) %>%
   step_dummy(all_nominal(), -all_outcomes()) %>%
   step_center(all_predictors(), -all_outcomes()) %>%
   step_scale(all_predictors(), -all_outcomes()) %>%
   prep(data = train_tbl)
        
```



```{r}
rec_obj
```

```{r}
x_train_tbl <- bake(rec_obj, new_data = train_tbl) %>% select(-Y)
x_test_tbl  <- bake(rec_obj, new_data = test_tbl) %>% select(-Y)

glimpse(x_train_tbl)
```


```{r}
y_train_vec <- pull(train_tbl, Y)
y_test_vec <- pull(test_tbl, Y)
```



```{r}
# Building our Artificial Neural Network
model_keras <- keras_model_sequential()

model_keras %>% 
  
  # First hidden layer
  layer_dense(
    units              = 16, 
    kernel_initializer = "uniform", 
    activation         = "relu", 
    input_shape        = ncol(x_train_tbl)) %>% 
  
  # Dropout to prevent overfitting
  layer_dropout(rate = 0.1) %>%
  
  # Second hidden layer
  layer_dense(
    units              = 16, 
    kernel_initializer = "uniform", 
    activation         = "relu") %>% 
  
  # Dropout to prevent overfitting
  layer_dropout(rate = 0.1) %>%
  
  # Output layer
  layer_dense(
    units              = 1, 
    kernel_initializer = "uniform", 
    activation         = "sigmoid") %>% 
  
  # Compile ANN
  compile(
    optimizer = 'adam',
    loss      = 'binary_crossentropy',
    metrics   = c('accuracy')
  )
model_keras

```

```{r}
# Fit the keras model to the training data
history <- fit(
  object           = model_keras, 
  x                = as.matrix(x_train_tbl), 
  y                = y_train_vec,
  batch_size       = 50, 
  epochs           = 35,
  validation_split = 0.30
)
```